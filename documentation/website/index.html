<!doctype html><html class="no-js"><head><meta charset="utf-8"><title>Project Title</title><meta name="description" content=""><meta name="viewport" content="width=device-width">
<!-- Place favicon.ico and apple-touch-icon.png in the root directory -->
<link href="http://fonts.googleapis.com/css?family=Raleway:300,400,600" rel="stylesheet" type="text/css">
<link rel="stylesheet" type="text/css" href="style.css">
        <script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>
        <!--<link rel="stylesheet" href="styles/main.37ab405b.css">-->
<body>
<script defer src="scripts/load_model_data.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" crossorigin="anonymous"></script>
<script defer src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js" crossorigin="anonymous"></script>

<!--[if lt IE 7]>
<p class="browsehappy">You are using an 
    <strong>outdated</strong> browser. Please 
    <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.
</p>
<![endif]-->
<div class="container">

    <nav class="navbar">
        <div class="container">
            <ul class="navbar-list">
                <li class="navbar-item">
                    <a class="navbar-link" href="#intro">Abstract</a>
                </li>
                <li class="navbar-item">
                    <a class="navbar-link" href="#intro">Intro</a>
                </li>
                <li class="navbar-item">
                    <a class="navbar-link" href="#method">Method</a>
                </li>
                <li class="navbar-item">
                    <a class="navbar-link" href="#experiments">Experiments</a>
                </li>
                <li class="navbar-item">
                    <a class="navbar-link" href="#discussion">Discussion</a>
                </li>
                <li class="navbar-item">
                    <a class="navbar-link" href="#appendix">Appendix</a>
                </li>
                <li class="navbar-item">
                    <a class="navbar-link" href="#references">References</a>
                </li>
            </ul>
        </div>
    </nav>

    <section class="header" id="abstract">
        <h2 class="title">ABC dataset segmentation with MeshCNN</h2>
        <h6>Project by Andr√©s Mandado (<a href="mailto:mandadoalmajano@campus.tu-berlin.de">mandadoalmajano@campus.tu-berlin.de"</a>)
        </h6>

        <div class="row">
<!--            <div class="one column category" style="text-align: center;">-->
<!--                <h5 class="docs-header">Teaser Image</h5>-->
                <img class="u-max-full-width" src="images/teaser.jpg">
                    <p>Abstract</p>
        </div>
    </section>

    <div class="docs-section" id="intro">
        <h3 class="section-heading">Introduction</h3>
        <h4 class="subsection-heading">MeshCNN</h4>
        <p>
            MeshCNN has different architectures for classification and segmentation. For segmentation,
            it uses a UNet architecture with residual learning blocks.
        </p>
        <figure>
            <img class="u-max-full-width" src="images/MeshCNN.svg">
            <figcaption>MeshCNN ResUNet</figcaption>
        </figure>
        <div>
            <p>MeshCNN uses mesh edges as primitives. For each each, it computes 5 input features:
            </p>
            <ul>
                <li>Dihedral angle between two incident faces</li>
                <li>2 opposite vertex angles</li>
                <li>2 ratios of edge length wrt triangle height</li>
            </ul>
            <div class="u-pull-right" style="width:20%">
                <figure>
                    <img class="u-max-full-width" src="images/input_features.svg">
                    <figcaption>Input Edge Features</figcaption>
                </figure>
                <figure>
                    <img class="u-max-full-width" src="images/mesh_conv.png">
                    <figcaption>Mesh Convolution</figcaption>
                </figure>
            </div>
            <img style="display:block;margin:auto" width="50%" src="images/input_vector.svg">
            <p>All these features are relative and implicitly invariant to translation, rotation and unform scaling.
            </p>
        </div>
        <p>Convolution is applied to the 1-ring neighbourhood of each edge, made of 5 edges (4 edges and itself). Edge
            order invariance is ensure by applying symmetric functions:
        </p>
        <img style="display:block;margin:auto" width="50%" src="images/neighbourhood.svg">
        <div style="clear:both;display: block"/>
         <p>In the pooling layer, a mesh is simplified to a target number of edges (model parameter) collapsing sequentially
             those edges with the smallest feature norm. A collapsed edge is removed and the features of the neighbouring
             edges are averaged by pairs. The correspondence between new and old edges is saved and used during unpooling to
             recover the original mesh structure.
        </p>
        <div style="width:50%; margin:auto">
            <figure>
                <img height="100%" width="100%" src="images/mesh_pool_unpool.png">
                <figcaption>Mesh Pooling/Unpooling</figcaption>
            </figure>
        </div>
        <h4 class="subsection-heading">ABC Dataset</h4>
    </div>

    <div class="docs-section" id="method">
        <h3 class="section-heading">Method</h3>
        <p class="section-description"></p>
        <h4 class="subsection-heading">MeshCNN improvements</h4>
        <p>Initial experiments showed that MeshCNN is not optimized to handle large meshes. The experiments in the
           original paper use datasets with small meshes, having at most a few thousand edges.<br>
           The first bottleneck is GPU memory usage, which grows quadratically with the number of mesh edges. Each pooling
            layer keeps in memory a tensor of edges^2 elements mapping edge collapses (<i>MeshUnion</i> class). This makes impossible training with half
            of the meshes in the ABC dataset (a single pooling operation in a 50K-edge mesh would allocate ~18GB of memory just for edge collapse bookkeeping!).
            The tensor though is inherently sparse, therefore we reimplemented the <i>MeshUnion</i> class and the <i>MeshUnpool</i> using <i>torch.sparse_coo_tensor</i>
            and sparse operations such as <i>torch.sparse.mm</i> and <i>torch.sparse.sum</i>. The memory consumption at function <i>create_GeMM</i> in
            the <i>MeshConv</i> layer was also reduced to less than a half by deleting temporary tensors once they're not needed and rewriting the symmetric
            functions so that they are done in place.<br>
            Another important bottleneck is that the edge collapsing at the MeshPool layer is done sequentially in CPU. As a result, MeshCNN training is
            CPU-bound and GPU utilization is low (under 30% in a NVIDIA Tesla P100). Training times become impractical for small datasets
            (9h per epoch for 1K meshes of 35K edges). To alleviate this problem, we modified MeshCNN code to allow for distributed training across multiple CPUs or
            even nodes. Using <i>torch.nn.parallel.DistributedDataParallel</i>, each batch is split and processed by identical instances of the model in separate devices,
            averaging the gradients for each node during the backwards pass.<br>
            Thanks to these optimizations we could train MeshCNN with ABC models of average size (~35K edges) and typical batch sizes (~10), having still room to increase
            the number of pooling layers.<br>
        </p>
        <h4 class="subsection-heading">Dataset preprocessing</h4>
        <p>As first preprocessing step for the compilation of dataset, we detect and exclude non-manifold meshes, since they're not supported by MeshCNN.<br>
            Additionally, small connected components (<10% of total faces) within a model are likely to become non-manifold during pooling. Therefore, models with such small
            components are also excluded.
        </p>
           <div class="row">
                <div class="one-half column category">
                    <h5 style="text-align:center">Non-manifold mesh (Model 34471)</h5>
                    <figure>
                        <img height="100%" width="100%" src="images/non_manifold_mesh_34471.png">
                    </figure>
                </div>
                <div class="one-half column category">
                    <h5 style="text-align:center">Small component (Model 49466)</h5>
                    <script class="model" src="models/49466_small_component.json" type="application/vnd.jupyter.widget-state+json"></script>
                    <script type="application/vnd.jupyter.widget-view+json">
                    {"version_major": 2, "version_minor": 0, "model_id": "94b8f1e32a54489c881eac3b91ce4dcc"}
                    </script>
                </div>
            </div>
    </div>


    <div class="docs-section" id="experiments">
        <h3 class="section-heading">Experiments</h3>
        <p class="section-description"></p>
        <div>
            <h4 class="subsection-heading">Ice breaker</h4>
            <div>
                <div class="u-pull-right-third">
                    <table class="u-full-width">
                            <tr>
                                <th>Train set size</th>
                                <td>262</td>
                            </tr>
                            <tr>
                                <th>Test set size</th>
                                <td>30</td>
                            </tr>
                            <tr>
                                <th>Mesh size</th>
                                <td><=5000 edges</td>
                            </tr>
                            <tr>
                                <th>Convolution #channels</th>
                                <td>32, 64, 128, 256</td>
                            </tr>
                            <tr>
                                <th>Pooling target sizes</th>
                                <td>4000, 3000, 1800</td>
                            </tr>
                            <tr>
                                <th>Batch size</th>
                                <td>4</td>
                            </tr>
                            <tr>
                                <th>Test accuracy</th>
                                <td>91.6% (15 epochs)</td>
                            </tr>
                    </table>
                </div>
                <p>In this first experiment we trained MeshCNN with a toy ABC subset of size and mesh resolutions similar to those
                    used in <a href="#1">[1]</a>, with the following objectives:
                </p>
                <ul>
                    <li>Validate training setup, label generation in particular</li>
                    <li>Early feasibility check</li>
                    <li>Identify potential changes required in MeshCNN and dataset preprocessing</li>
                </ul>
                <p>As a result of the experiment, we identified the memory and processing bottlenecks as well as required preprocessing steps
                explained in the <a href="#method">methodology</a>.</p>.
            </div>
            <div style="clear:both;display: block"/>
            <div>
                <h5 style="text-align:center">Model 36631 (prediction)</h5>
                <script class="model" src="models/36631.json" type="application/vnd.jupyter.widget-state+json"></script>
                <script type="application/vnd.jupyter.widget-view+json">
                {"version_major": 2, "version_minor": 0, "model_id": "6c90cad6836149d7a89e244e20cc9dde"}
            </script>
                <table width="100%" style="table-layout: fixed">
                    <tbody class="surface-types-table">
                        <tr>
                            <td class="surface-types" style="background-color:red">Plane</td>
                            <td class="surface-types" style="background-color:blue">Cylinder</td>
                            <td class="surface-types" style="background-color:magenta">Cone</td>
                            <td class="surface-types" style="background-color:purple">Torus</td>
                            <td class="surface-types" style="background-color:black">BSpline</td>
                            <td class="surface-types" style="background-color:orange">Sphere</td>
                            <td class="surface-types" style="background-color:green">Revolution</td>
                            <td class="surface-types" style="background-color:cyan">Extrusion</td>
                            <td class="surface-types" style="background-color:yellow">Other</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>
        <div>
            <h4 class="subsection-heading">Medium dataset</h4>
            <div class="u-pull-right-third">
                    <table class="u-full-width">
                            <tr>
                                <th>Train set size</th>
                                <td>862</td>
                            </tr>
                            <tr>
                                <th>Test set size</th>
                                <td>93</td>
                            </tr>
                            <tr>
                                <th>Mesh size</th>
                                <td>[33000,35000] edges</td>
                            </tr>
                            <tr>
                                <th>Convolution #channels</th>
                                <td>32, 64, 128, 256</td>
                            </tr>
                            <tr>
                                <th>Pooling target sizes</th>
                                <td>20000, 15000, 10000</td>
                            </tr>
                            <tr>
                                <th>Batch size</th>
                                <td>10</td>
                            </tr>
                            <tr>
                                <th>Test accuracy</th>
                                <td>89.5% (19 epochs)</td>
                            </tr>
                    </table>
            </div>
            <p>Onced the issues observed in the first experiment were solved a second larger dataset was compiled with meshes of
                sizes close to the ABC average. The meshes in the dataset have size differences (in #edges) of at most 10%, since
                mixing mesh of very different sizes may have an impact on the network performance (as is the case with CNNs for images).
            </p>
            <div style="clear:both;display: block"/>
            <div class="row">
                <div class="one-half column category">
                    <h5 style="text-align:center">Model 38019 (prediction)</h5>
                    <script class="model" src="models/38019_pred.json" type="application/vnd.jupyter.widget-state+json"></script>
                    <script type="application/vnd.jupyter.widget-view+json">
    {"version_major": 2, "version_minor": 0, "model_id": "6579d789b1af4d3c8a003277cd08db58"}
    </script>
                </div>
                <div class="one-half column category">
                    <h5 style="text-align:center">Model 38019 (ground truth)</h5>
                    <script class="model" src="models/38019_truth.json" type="application/vnd.jupyter.widget-state+json"></script>
                    <script type="application/vnd.jupyter.widget-view+json">
    {"version_major": 2, "version_minor": 0, "model_id": "c890054592ea4b1886731e2997ca026e"}
    </script>
                </div>
                <table class="u-full-width">
                    <tbody class="surface-types-table">
                        <tr>
                            <td class="surface-types" style="background-color:red">Plane</td>
                            <td class="surface-types" style="background-color:blue">Cylinder</td>
                            <td class="surface-types" style="background-color:magenta">Cone</td>
                            <td class="surface-types" style="background-color:purple">Torus</td>
                            <td class="surface-types" style="background-color:black">BSpline</td>
                            <td class="surface-types" style="background-color:orange">Sphere</td>
                            <td class="surface-types" style="background-color:green">Revolution</td>
                            <td class="surface-types" style="background-color:cyan">Extrusion</td>
                            <td class="surface-types" style="background-color:yellow">Other</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="row">
                <div class="one-half column category">
                    <h5 style="text-align:center">Model 38191 (prediction)</h5>
                     <script class="model" src="models/38191_pred.json" type="application/vnd.jupyter.widget-state+json"></script>
                    <script type="application/vnd.jupyter.widget-view+json">
    {"version_major": 2, "version_minor": 0, "model_id": "5c7ac1c66a87465380401a42895e09d3"}
    </script>
                </div>
                <div class="one-half column category">
                    <h5 style="text-align:center">Model 38191 (ground truth)</h5>
                    <script class="model" src="models/38191_truth.json" type="application/vnd.jupyter.widget-state+json"></script>
                    <script type="application/vnd.jupyter.widget-view+json">
    {"version_major": 2, "version_minor": 0, "model_id": "73e2c1b19d954ba694b96d22fd9646dc"}
    </script>
                </div>
                <table class="u-full-width">
                    <tbody class="surface-types-table">
                        <tr>
                            <td class="surface-types" style="background-color:red">Plane</td>
                            <td class="surface-types" style="background-color:blue">Cylinder</td>
                            <td class="surface-types" style="background-color:magenta">Cone</td>
                            <td class="surface-types" style="background-color:purple">Torus</td>
                            <td class="surface-types" style="background-color:black">BSpline</td>
                            <td class="surface-types" style="background-color:orange">Sphere</td>
                            <td class="surface-types" style="background-color:green">Revolution</td>
                            <td class="surface-types" style="background-color:cyan">Extrusion</td>
                            <td class="surface-types" style="background-color:yellow">Other</td>
                        </tr>
                    </tbody>
            </table>
            </div>
             <div class="u-pull-right" style="width:50%; margin-left:20px">
                <figure>
                    <img class="u-max-full-width" src="images/class_imbalance_chart.svg">
                    <figcaption>Edge class frequencies on medium dataset</figcaption>
                </figure>
            </div>
             <p> The model learns to predict the two most frequent classes (plane and cylinder surfaces), but no the rest. The optimization seems to stay at a local minima in the loss
                function, most probably due to the imbalance in the class occurrence.
            </p>
        </div>
        <div style="clear:both;display: block"/>
        <h4 class="subsection-heading">Medium dataset (weighted)</h4>
        <p>To escape the local minima reached in the previous experiment, we apply weights to the loss function (torch.nn.CrossEntropyLoss) inversely proportional to class occurrence in train set.</p>
        <h4 class="subsection-heading">Medium dataset (resampled & weighted)</h4>
        <p>This experiment uses a new dataset compiled oversampling the underrepresented classes and undersampling the most frequent ones. The remaining class imbalance is compensated by loss
        function adjustments as in the previous experiment.</p>
    </div>

    <div class="docs-section" id="discussion">
        <h3 class="section-heading">Discussion and Future Work</h3>
        <p class="section-description"></p>
    </div>

    <div class="docs-section" id="appendix">
        <h3 class="section-heading">Appendix</h3>
        <ul>
            <li>Presentations
              <ol>
                <li>Project proposal</li>
                <li>Tech presentation</li>
              </ol>
            </li>
        </ul>
    </div>

    <div class="docs-section" id="references">
        <h3 class="section-heading">References</h3>
        <ul class="popover-list">
            <li class="popover-item" id="1">
                <!--A link to this may look like: <a href="#1">[1]</a>-->
                [1] Rana Hanocka, Amir Hertz, Noa Fish, Raja Giryes, Shachar Fleishman and Daniel Cohen-Or. 2019. MeshCNN: A Network with an Edge. <i>ACM Trans. Graph. 1, 1 (Feb 2019). </i><a href="https://ranahanocka.github.io/MeshCNN"> https://ranahanocka.github.io/MeshCNN</a>
            </li>
          
            <li class="popover-item" id="2">
                [2] Koch, Sebastian and Matveev, Albert and Jiang, Zhongshi and Williams, Francis and Artemov, Alexey and Burnaev, Evgeny and Alexa, Marc and Zorin, Denis and Panozzo, Daniele. 2019. ABC: A Big CAD Model Dataset For Geometric Deep Learning. <i>The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (June 2019). </i><a href="https://deep-geometry.github.io/abc-dataset"> https://deep-geometry.github.io/abc-dataset</a>
            </li>
            
        </ul>
    </div>

</div>

